{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WhK-uDq7F5EwVO69SLKZoMEGD7zcp0zM",
      "authorship_tag": "ABX9TyNlH6mXMatgpuCh15XKI3US",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreeya22/Enhancing-Crop-Health-Image-Classification-of-Plant-Diseases/blob/main/leaf_detect_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijSsuYQX_TI0",
        "outputId": "96287d8f-0b16-4471-d3a6-f77281e12e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "#initialize nn\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "#convert pooling features space to large feature vector for fully\n",
        "#connected layer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "\n",
        "#basic cnn\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(128,128, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(25, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = None,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/AEC dataset/dataset/train',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "#print(test_datagen);\n",
        "labels = (training_set.class_indices)\n",
        "print(labels)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/AEC dataset/dataset/test',\n",
        "                                            target_size = (128, 128),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "labels2 = (test_set.class_indices)\n",
        "print(labels2)\n",
        "\n",
        "model.fit(training_set,\n",
        "                         steps_per_epoch = 375,\n",
        "                         epochs = 10,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 125)\n",
        "\n",
        "\n",
        "# Part 3 - Making new predictions\n",
        "\n",
        "model_json=model.to_json()\n",
        "with open(\"model1.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "    model.save_weights(\"model1.weights.h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMW0AlMzY1I3",
        "outputId": "15bc7a4d-74e5-4dd2-ea80-b7e406491b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 375 images belonging to 25 classes.\n",
            "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___Healthy': 3, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 4, 'Corn_(maize)___Common_rust': 5, 'Corn_(maize)___Healthy': 6, 'Corn_(maize)___Northern_Leaf_Blight': 7, 'Grape___Black_rot': 8, 'Grape___Esca_(Black_Measles)': 9, 'Grape___Healthy': 10, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 11, 'Potato___Early_blight': 12, 'Potato___Healthy': 13, 'Potato___Late_blight': 14, 'Tomato___Bacterial_spot': 15, 'Tomato___Early_blight': 16, 'Tomato___Healthy': 17, 'Tomato___Late_blight': 18, 'Tomato___Leaf_Mold': 19, 'Tomato___Septoria_leaf_spot': 20, 'Tomato___Spider_mites Two-spotted_spider_mite': 21, 'Tomato___Target_Spot': 22, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 23, 'Tomato___Tomato_mosaic_virus': 24}\n",
            "Found 127 images belonging to 25 classes.\n",
            "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___Healthy': 3, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 4, 'Corn_(maize)___Common_rust_': 5, 'Corn_(maize)___Healthy': 6, 'Corn_(maize)___Northern_Leaf_Blight': 7, 'Grape___Black_rot': 8, 'Grape___Esca_(Black_Measles)': 9, 'Grape___Healthy': 10, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 11, 'Potato___Early_blight': 12, 'Potato___Healthy': 13, 'Potato___Late_blight': 14, 'Tomato___Bacterial_spot': 15, 'Tomato___Early_blight': 16, 'Tomato___Healthy': 17, 'Tomato___Late_blight': 18, 'Tomato___Leaf_Mold': 19, 'Tomato___Septoria_leaf_spot': 20, 'Tomato___Spider_mites Two-spotted_spider_mite': 21, 'Tomato___Target_Spot': 22, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 23, 'Tomato___Tomato_mosaic_virus': 24}\n",
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.0766 - loss: 3.4575 - val_accuracy: 0.0472 - val_loss: 3.2244\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.1779 - loss: 2.9567 - val_accuracy: 0.0394 - val_loss: 3.2619\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.2415 - loss: 2.6398 - val_accuracy: 0.0394 - val_loss: 3.3104\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.2957 - loss: 2.3887 - val_accuracy: 0.0394 - val_loss: 3.4093\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.3897 - loss: 2.1254 - val_accuracy: 0.0394 - val_loss: 3.5264\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.3979 - loss: 1.9384 - val_accuracy: 0.0394 - val_loss: 3.7189\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.5282 - loss: 1.6967 - val_accuracy: 0.0394 - val_loss: 3.7060\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.5307 - loss: 1.5939 - val_accuracy: 0.0394 - val_loss: 3.9800\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.5551 - loss: 1.5311 - val_accuracy: 0.0394 - val_loss: 4.2500\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.5871 - loss: 1.4203 - val_accuracy: 0.0394 - val_loss: 4.7414\n",
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbAQOFQv1QZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119f6dd5-6a4d-4c72-b1ba-43b13b0cb995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "Predicted label for image 1: Tomato___Spider_mites Two-spotted_spider_mite\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicted class index for image 2: 19\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import model_from_json\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Load the model from JSON and weights\n",
        "json_file_path = 'model1.json'\n",
        "weights_file_path = 'model1.weights.h5'\n",
        "\n",
        "# Check if the model files exist\n",
        "if not os.path.isfile(json_file_path) or not os.path.isfile(weights_file_path):\n",
        "    raise FileNotFoundError(\"Model files not found. Check the file paths.\")\n",
        "\n",
        "# Load model architecture and weights\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(weights_file_path)\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# Labels for the model\n",
        "label = [\"Apple___Apple_scab\", \"Apple___Black_rot\", \"Apple___Cedar_apple_rust\", \"Apple___Healthy\",\n",
        "         \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\", \"Corn_(maize)___Common_rust_\",\n",
        "         \"Corn_(maize)___Healthy\", \"Corn_(maize)___Northern_Leaf_Blight\", \"Grape___Black_rot\",\n",
        "         \"Grape___Esca_(Black_Measles)\", \"Grape___Healthy\", \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
        "         \"Potato___Early_blight\", \"Potato___Healthy\", \"Potato___Late_blight\", \"Tomato___Bacterial_spot\",\n",
        "         \"Tomato___Early_blight\", \"Tomato___Healthy\", \"Tomato___Late_blight\", \"Tomato___Leaf_Mold\",\n",
        "         \"Tomato___Septoria_leaf_spot\", \"Tomato___Spider_mites Two-spotted_spider_mite\", \"Tomato___Target_Spot\",\n",
        "         \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\", \"Tomato___Tomato_mosaic_virus\"]\n",
        "\n",
        "# Function to preprocess and predict an image\n",
        "def preprocess_and_predict(image_path, model, label_list):\n",
        "    # Load and preprocess image\n",
        "    img = image.load_img(image_path, target_size=(128, 128))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict class\n",
        "    prediction = model.predict(img)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Ensure the predicted class index is valid\n",
        "    if predicted_class >= len(label_list):\n",
        "        raise IndexError(\"Predicted class index is out of range for the label list.\")\n",
        "\n",
        "    return label_list[predicted_class]\n",
        "\n",
        "# Test image 1\n",
        "test_image_path1 = '/content/drive/MyDrive/AEC dataset/im_for_testing_purpose/t.lateblight.JPG'\n",
        "predicted_label1 = preprocess_and_predict(test_image_path1, loaded_model, label)\n",
        "print(f\"Predicted label for image 1: {predicted_label1}\")\n",
        "\n",
        "# Test image 2\n",
        "test_image_path2 = '/content/drive/MyDrive/AEC dataset/im_for_testing_purpose/t.yelloleafcurls.JPG'\n",
        "\n",
        "# Check if the second image file exists\n",
        "if not os.path.isfile(test_image_path2):\n",
        "    raise FileNotFoundError(f\"The file {test_image_path2} does not exist.\")\n",
        "\n",
        "# Load and preprocess image using OpenCV\n",
        "test_image = cv2.imread(test_image_path2)\n",
        "if test_image is None:\n",
        "    raise ValueError(\"Image file could not be loaded. Check the file path and format.\")\n",
        "\n",
        "test_image = cv2.resize(test_image, (128, 128))  # Resize to match the model input size\n",
        "test_image = test_image / 255.0  # Normalize pixel values to [0, 1]\n",
        "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Predict class\n",
        "prediction = loaded_model.predict(test_image)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Define labels for this classification\n",
        "label2 = [\"cats\", \"dogs\", \"horse\", \"rose\"]\n",
        "\n",
        "# Print predicted class index for debugging\n",
        "print(f\"Predicted class index for image 2: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Define the enhanced CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(25, activation='softmax'))\n",
        "\n",
        "# Compile the model with an adjusted learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation with rescaling\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/AEC dataset/dataset/train',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/AEC dataset/dataset/test',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    training_set,\n",
        "    steps_per_epoch=2,\n",
        "    epochs=2,\n",
        "    validation_data=test_set,\n",
        "    validation_steps=50,\n",
        "    verbose=2  # Change verbosity to get more detailed output\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model1.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model1.weights.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNS2qC4d7IzF",
        "outputId": "583ecaf6-0372-4210-8ce5-dc374e4b8114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 375 images belonging to 25 classes.\n",
            "Found 127 images belonging to 25 classes.\n",
            "Epoch 1/2\n",
            "2/2 - 12s - 6s/step - accuracy: 0.0469 - loss: 9.0332 - val_accuracy: 0.0472 - val_loss: 8.8082\n",
            "Epoch 2/2\n",
            "2/2 - 4s - 2s/step - accuracy: 0.0000e+00 - loss: 9.3554 - val_accuracy: 0.0394 - val_loss: 8.8037\n",
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LpLjjJsOwZdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}